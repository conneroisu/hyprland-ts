# Testing Guide for hyprland-ts\n\nThis document outlines the comprehensive testing strategy, patterns, and best practices used in the hyprland-ts project.\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Test Types](#test-types)\n- [Test Structure](#test-structure)\n- [Running Tests](#running-tests)\n- [Writing Tests](#writing-tests)\n- [Best Practices](#best-practices)\n- [Coverage Requirements](#coverage-requirements)\n- [CI/CD Pipeline](#cicd-pipeline)\n\n## Overview\n\nThe hyprland-ts project employs a multi-layered testing strategy to ensure reliability, performance, and correctness:\n\n- **Unit Tests**: Test individual functions and type definitions\n- **Integration Tests**: Test complete workflows with mocked Hyprland instances\n- **Property-Based Tests**: Test invariants and edge cases using generated data\n- **Performance Tests**: Ensure scalability and resource efficiency\n- **Edge Case Tests**: Test boundary conditions and error scenarios\n\n## Test Types\n\n### 1. Unit Tests\n\n**Location**: `src/*.unit.test.ts`\n\n**Purpose**: Test individual components in isolation\n\n**Example**:\n```typescript\ntest('should validate correct window objects', () => {\n  const window = createMockWindow();\n  const result = validateHyprlandWindow(window);\n  \n  expect(result.success).toBe(true);\n  expect(result.data).toEqual(window);\n});\n```\n\n### 2. Integration Tests\n\n**Location**: `src/integration.test.ts`\n\n**Purpose**: Test complete workflows and IPC communication\n\n**Features**:\n- Mock Hyprland server implementation\n- End-to-end command execution\n- Event handling simulation\n- Error scenario testing\n\n**Example**:\n```typescript\ntest('should complete window management workflow', async () => {\n  // 1. Get initial state\n  let response = await commandSocket.send(JSON.stringify(createMockHyprCtlRequest('clients')));\n  \n  // 2. Execute commands\n  response = await commandSocket.send(JSON.stringify(createMockHyprCtlRequest('dispatch', ['exec', 'test-app'])));\n  \n  // 3. Verify results\n  expect(JSON.parse(response).success).toBe(true);\n});\n```\n\n### 3. Property-Based Tests\n\n**Location**: `src/property.test.ts`\n\n**Purpose**: Test invariants using generated data\n\n**Tools**: `fast-check` library for data generation\n\n**Example**:\n```typescript\ntest('validateHyprlandWindow should always succeed for valid windows', () => {\n  fc.assert(\n    fc.property(arbWindow(), (window) => {\n      const result = validateHyprlandWindow(window);\n      expect(result.success).toBe(true);\n    }),\n    { numRuns: 100 }\n  );\n});\n```\n\n### 4. Performance Tests\n\n**Location**: `src/performance.test.ts`\n\n**Purpose**: Ensure scalability and performance\n\n**Metrics**:\n- Operations per second\n- Memory usage\n- Execution time\n- Scalability patterns\n\n**Example**:\n```typescript\ntest('validation should scale linearly with array size', () => {\n  const metrics = measurePerformance(() => {\n    validateHyprlandWindow(window);\n  }, 1000);\n  \n  expect(metrics.operationsPerSecond).toBeGreaterThan(100);\n});\n```\n\n### 5. Edge Case Tests\n\n**Location**: `src/edge-cases.test.ts`\n\n**Purpose**: Test boundary conditions and error scenarios\n\n**Coverage**:\n- Extreme numeric values\n- Malformed data\n- Unicode edge cases\n- Memory pressure scenarios\n\n## Test Structure\n\n### File Organization\n\n```\nsrc/\n├── types.ts                    # Type definitions\n├── validation.ts               # Validation logic\n├── test-utils.ts              # Test utilities and mocks\n├── types.unit.test.ts         # Unit tests for types\n├── validation.unit.test.ts    # Unit tests for validation\n├── integration.test.ts        # Integration tests\n├── property.test.ts           # Property-based tests\n├── performance.test.ts        # Performance tests\n└── edge-cases.test.ts         # Edge case tests\n```\n\n### Test Utilities\n\nThe `test-utils.ts` file provides:\n\n- **Mock Data Generators**: Create realistic test data\n- **Test Assertions**: Custom assertion helpers\n- **Mock IPC Server**: Simulate Hyprland communication\n- **Performance Measurement**: Benchmark utilities\n\n```typescript\n// Example usage\nconst window = createMockWindow({\n  title: 'Custom Title',\n  floating: true,\n});\n\nconst cluster = createWindowCluster(10);\nconst dataset = createLargeDataset(1000);\n```\n\n## Running Tests\n\n### Basic Commands\n\n```bash\n# Run all tests\nnpm test\n\n# Run tests with coverage\nnpm run test:coverage\n\n# Run specific test file\nnpm test -- src/validation.unit.test.ts\n\n# Run tests in watch mode\nnpm test -- --watch\n\n# Run tests with UI\nnpm run test:ui\n```\n\n### Test Categories\n\n```bash\n# Unit tests only\nnpm test -- src/*.unit.test.ts\n\n# Integration tests\nnpm test -- src/integration.test.ts\n\n# Performance tests\nnpm test -- src/performance.test.ts\n\n# Property-based tests\nnpm test -- src/property.test.ts\n\n# Edge case tests\nnpm test -- src/edge-cases.test.ts\n```\n\n### Coverage Reports\n\n```bash\n# Generate coverage report\nnpm run test:coverage\n\n# View HTML coverage report\nopen coverage/index.html\n```\n\n## Writing Tests\n\n### Test Naming Convention\n\n- **Files**: `*.test.ts` or `*.spec.ts`\n- **Describe blocks**: Use descriptive names that indicate the component being tested\n- **Test cases**: Use \"should\" statements that describe expected behavior\n\n```typescript\ndescribe('HyprlandWindow Validation', () => {\n  describe('when validating correct windows', () => {\n    test('should return success for valid window objects', () => {\n      // Test implementation\n    });\n    \n    test('should preserve all window properties', () => {\n      // Test implementation\n    });\n  });\n  \n  describe('when validating invalid windows', () => {\n    test('should return detailed error messages', () => {\n      // Test implementation\n    });\n  });\n});\n```\n\n### Mock Data Best Practices\n\n1. **Use Factory Functions**: Create reusable mock generators\n2. **Realistic Data**: Base mocks on actual Hyprland responses\n3. **Partial Overrides**: Allow customization of specific properties\n4. **Edge Cases**: Create dedicated edge case generators\n\n```typescript\n// Good: Flexible factory function\nconst window = createMockWindow({\n  floating: true,\n  at: [100, 200] as const,\n});\n\n// Bad: Hardcoded values\nconst window = {\n  address: '0x123',\n  mapped: true,\n  // ... all properties hardcoded\n};\n```\n\n### Assertion Patterns\n\n```typescript\n// Structure validation\nexpect(result).toHaveProperty('success');\nexpect(result.success).toBe(true);\n\n// Array validation\nexpect(Array.isArray(windows)).toBe(true);\nexpect(windows).toHaveLength(expectedCount);\n\n// Error validation\nexpect(result.success).toBe(false);\nexpect(result.errors).toBeDefined();\nexpect(result.errors!.length).toBeGreaterThan(0);\n\n// Performance validation\nexpect(metrics.duration).toBeLessThan(1000);\nexpect(metrics.operationsPerSecond).toBeGreaterThan(100);\n```\n\n## Best Practices\n\n### 1. Test Independence\n\n- Each test should be independent and not rely on other tests\n- Use `beforeEach`/`afterEach` for setup and cleanup\n- Avoid shared mutable state between tests\n\n### 2. Clear Test Names\n\n- Use descriptive test names that explain the scenario\n- Include the expected outcome in the test name\n- Group related tests using `describe` blocks\n\n### 3. Mock Management\n\n- Keep mocks simple and focused\n- Reset mocks between tests\n- Use realistic mock data based on actual API responses\n\n### 4. Error Testing\n\n- Test both success and failure paths\n- Verify error messages are helpful\n- Test edge cases and boundary conditions\n\n### 5. Performance Considerations\n\n- Include performance tests for critical paths\n- Set reasonable performance thresholds\n- Test scalability with varying data sizes\n\n### 6. Documentation\n\n- Document complex test scenarios\n- Explain the reasoning behind edge case tests\n- Provide examples for common testing patterns\n\n## Coverage Requirements\n\nThe project maintains strict coverage requirements:\n\n- **Statements**: 90%\n- **Branches**: 90%\n- **Functions**: 90%\n- **Lines**: 90%\n\n### Coverage Exclusions\n\n- Test files (`*.test.ts`, `*.spec.ts`)\n- Test utilities (`test-utils.ts`)\n- Build configuration files\n- Type definition files (`*.d.ts`)\n\n### Monitoring Coverage\n\n```bash\n# Check coverage\nnpm run test:coverage\n\n# Coverage will fail if below thresholds\nnpm run test:coverage -- --reporter=verbose\n```\n\n## CI/CD Pipeline\n\nThe GitHub Actions workflow runs comprehensive tests:\n\n### Test Matrix\n\n- **Node.js versions**: 18.x, 20.x, 22.x\n- **Test types**: Unit, Integration, Performance, Property-based, Edge cases\n- **Additional checks**: Linting, Type checking, Security audit\n\n### Workflow Stages\n\n1. **Basic Tests**: Unit tests across Node.js versions\n2. **Specialized Tests**: Performance, property-based, edge cases\n3. **Integration Tests**: End-to-end workflows\n4. **Build Tests**: Package building and importing\n5. **Security Audit**: Dependency vulnerability scanning\n\n### Artifacts\n\n- Test results (JSON/HTML)\n- Coverage reports\n- Performance metrics\n- Build artifacts\n\n### Quality Gates\n\n- All tests must pass\n- Coverage thresholds must be met\n- No high-severity security vulnerabilities\n- Successful package build\n\n## Troubleshooting\n\n### Common Issues\n\n1. **TypeScript Errors in Tests**\n   - Ensure test files are included in `tsconfig.json`\n   - Check import paths and type definitions\n\n2. **Slow Performance Tests**\n   - Adjust iteration counts for CI environment\n   - Use appropriate test timeouts\n\n3. **Flaky Integration Tests**\n   - Add proper async/await handling\n   - Increase timeouts for mock operations\n\n4. **Coverage Issues**\n   - Check if files are properly excluded\n   - Ensure all code paths are tested\n\n### Debug Commands\n\n```bash\n# Run tests with debug output\nnpm test -- --reporter=verbose\n\n# Run specific test with debugging\nnpm test -- --reporter=verbose src/validation.unit.test.ts\n\n# Check TypeScript compilation\nnpm run type-check\n```\n\n## Contributing\n\nWhen adding new features:\n\n1. **Write Tests First**: Follow TDD principles\n2. **Update Documentation**: Include testing examples\n3. **Maintain Coverage**: Ensure new code is fully tested\n4. **Add Edge Cases**: Consider boundary conditions\n5. **Performance Impact**: Include performance tests for critical paths\n\nFor more information, see the main [README.md](./README.md) and [CONTRIBUTING.md](./CONTRIBUTING.md) files."